<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7603480</article-id><article-id pub-id-type="publisher-id">19267</article-id><article-id pub-id-type="doi">10.1038/s41467-020-19267-x</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Machine learning in chemical reaction space</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4144-0371</contrib-id><name><surname>Stocker</surname><given-names>Sina</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8180-2034</contrib-id><name><surname>Cs&#x000e1;nyi</surname><given-names>G&#x000e1;bor</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8473-8659</contrib-id><name><surname>Reuter</surname><given-names>Karsten</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0862-5289</contrib-id><name><surname>Margraf</surname><given-names>Johannes T.</given-names></name><address><email>johannes.margraf@ch.tum.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution>Chair of Theoretical Chemistry and Catalysis Research Center, </institution><institution>Technische Universit&#x000e4;t M&#x000fc;nchen, </institution></institution-wrap>Garching, Germany </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.5335.0</institution-id><institution-id institution-id-type="ISNI">0000000121885934</institution-id><institution>Engineering Laboratory, </institution><institution>University of Cambridge, </institution></institution-wrap>Cambridge, CB2 1PZ UK </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.418028.7</institution-id><institution-id institution-id-type="ISNI">0000 0001 0565 1775</institution-id><institution>Fritz-Haber-Institut der Max-Planck-Gesellschaft, </institution></institution-wrap>Berlin, Germany </aff></contrib-group><pub-date pub-type="epub"><day>30</day><month>10</month><year>2020</year></pub-date><pub-date pub-type="pmc-release"><day>30</day><month>10</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>11</volume><elocation-id>5505</elocation-id><history><date date-type="received"><day>13</day><month>5</month><year>2020</year></date><date date-type="accepted"><day>1</day><month>10</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2020</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Chemical compound space refers to the vast set of all possible chemical compounds, estimated to contain 10<sup>60</sup> molecules. While intractable as a whole, modern machine learning (ML) is increasingly capable of accurately predicting molecular properties in important subsets. Here, we therefore engage in the ML-driven study of even larger reaction space. Central to chemistry as a science of transformations, this space contains all possible chemical reactions. As an important basis for &#x02018;reactive&#x02019; ML, we establish a first-principles database (Rad-6) containing closed and open-shell organic molecules, along with an associated database of chemical reaction energies (Rad-6-RE). We show that the special topology of reaction spaces, with central hub molecules involved in multiple reactions, requires a modification of existing compound space ML-concepts. Showcased by the application to methane combustion, we demonstrate that the learned reaction energies offer a non-empirical route to rationally extract reduced reaction networks for detailed microkinetic analyses.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Application of machine-learning approaches to exploring chemical reaction networks is challenging due to need of including open-shell reaction intermediates. Here the authors introduce a density functional theory database of closed and open-shell molecules for machine-learning predictions of reaction energies.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Catalysis</kwd><kwd>Physical chemistry</kwd><kwd>Computational chemistry</kwd><kwd>Density functional theory</kwd><kwd>Method development</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft (German Research Foundation)</institution></institution-wrap></funding-source><award-id>GSC81</award-id><principal-award-recipient><name><surname>Margraf</surname><given-names>Johannes T.</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2020</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Reaction networks are essential tools for the description, illustration, and fundamental understanding of chemical processes in such diverse fields as catalysis<sup><xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR4">4</xref></sup>, combustion<sup><xref ref-type="bibr" rid="CR5">5</xref>&#x02013;<xref ref-type="bibr" rid="CR7">7</xref></sup>, polymerization<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, atmospheric chemistry<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, systems chemistry<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>, and the origin of life<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Indeed, any study of chemical kinetics or selectivity is essentially a study of a reaction network. In many cases, however, the understanding of complex chemical processes is hampered by the&#x000a0;sheer size of the networks in question<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref></sup>. For example, we recently reported a database of over 1 million elementary reactions for molecules no larger than four non-hydrogen atoms containing carbon, oxygen and hydrogen<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>.</p><p id="Par4">The reaction networks typically used in microkinetic studies of natural and industrial processes are therefore necessarily merely sub-graphs of the full network of possible reactions (see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>)<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. This is not automatically a problem, as large parts of the latter may not be thermodynamically accessible. It is therefore entirely possible that a microkinetic model based on a reduced reaction network correctly describes the overall kinetics of a complex process<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. Meanwhile, the big advantage of focusing on sub-graphs is that the kinetics and thermochemistry of each elementary step may be explicitly computed from first principles. This offers a non-empirical route to understanding complex reaction mechanisms.<fig id="Fig1"><label>Fig. 1</label><caption><title>Visualization of chemical reaction spaces as graphs with molecules as nodes and reactions as edges.</title><p><bold>a</bold> Full network of bond dissociation reactions for carbon-, oxygen-, hydrogen-containing molecules with up to four heavy atoms. <bold>b</bold> Reduced reaction network of the initial steps of natural gas combustion. Nodes are colored according to the number of incident edges/reactions (their degree) from low (white) to high (dark green).</p></caption><graphic xlink:href="41467_2020_19267_Fig1_HTML" id="d30e376"/></fig></p><p id="Par5">Notwithstanding, the difficulty lies in knowing which parts of the full network to keep. One would need at least an approximate notion of the reaction thermochemistry (and ideally the kinetics) of the full network, to be able to do this on a rational basis. This information is typically not available. Indeed, not even the topology of the full network is usually taken into account. Instead, state-of-the-art reaction networks are generally built by hand, based on chemical intuition and (sparse) experimental evidence. The frequently observed failure to correctly predict the selectivities of complex catalytic processes with first&#x02013;principles microkinetics indicates that such ad hoc networks may miss important links<sup><xref ref-type="bibr" rid="CR24">24</xref>&#x02013;<xref ref-type="bibr" rid="CR26">26</xref></sup>.</p><p id="Par6">The central impediment towards a non-empirical construction of reduced reaction networks is the large computational cost of first-principles electronic structure methods such as density-functional theory (DFT). It is simply not feasible to routinely compute tens or hundreds of thousands of reaction energies (REs) and activation barriers. In this context, machine-learning (ML) models that are trained on a limited number of DFT calculations have recently emerged as powerful tools for the high-throughput prediction of molecular and materials properties<sup><xref ref-type="bibr" rid="CR27">27</xref>&#x02013;<xref ref-type="bibr" rid="CR33">33</xref></sup>. Simply put, ML can be used to interpolate properties (such as energies) across chemical compound space. State-of-the-art methods actually surpass chemical accuracy (ca. 0.05&#x02009;eV) when applied to standard benchmarks like the QM9 database<sup><xref ref-type="bibr" rid="CR34">34</xref>&#x02013;<xref ref-type="bibr" rid="CR38">38</xref></sup>. Similarly, ML models can be applied to conformational space (e.g., when trained on ab initio molecular dynamics trajectories) or even interpolate across chemical and conformational space at the same time<sup><xref ref-type="bibr" rid="CR39">39</xref>&#x02013;<xref ref-type="bibr" rid="CR41">41</xref></sup>.</p><p id="Par7">While exploring compound space is useful in its own right (e.g., for drug or materials design), chemistry is the science of transformations in chemical space. In contrast, virtually all ML models for organic molecules to date are trained on reference data derived from the chemical universe database of Reymond and coworkers, which enumerates potentially stable, drug-like molecules<sup><xref ref-type="bibr" rid="CR41">41</xref>&#x02013;<xref ref-type="bibr" rid="CR43">43</xref></sup>. Almost by construction, these models therefore cannot describe elementary reactions such as the ones shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, which typically involve radical or charged intermediates. In our view, the application of ML to areas like catalysis and combustion requires a shift of focus from stable molecules to radicals (i.e., the nodes in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) and to reactions (the edges). The goal of this paper is therefore to begin the development of ML models for the exploration of reaction space, as opposed to compound space.</p><p id="Par8">Specifically, we introduce a new DFT database of closed- and open-shell molecules that covers an extensive network of chemical reactions. We then develop ML models to predict atomization and REs. Finally, the models are used to explore the reaction network of methane combustion and identify the most relevant reaction steps and fragments out of a large initial database.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Data and kernels</title><p id="Par9">To train reactive ML models, a reference database of both open and closed-shell systems must be established. A large set of such structures was enumerated using a graph-based approach<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, and the ground-state geometry and energy of each system was determined with DFT calculations using the hybrid PBE0 functional with Tkatchenko-Scheffler dispersion corrections<sup><xref ref-type="bibr" rid="CR44">44</xref>&#x02013;<xref ref-type="bibr" rid="CR46">46</xref></sup>. The resulting Rad-6 reference database comprises 10,712 molecules containing carbon, oxygen and hydrogen, the largest of which consists of six non-hydrogen atoms. As illustrated in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, this dataset is rich in unconventional structural motifs, such as poly-radicals. As is commonly observed, the space of possible compounds scales exponentially with the system size (see Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, left). This figure also reveals that radical fragments in fact dominate the database, as they are combinatorically much more frequent (by an order of magnitude) than closed-shell systems. Notably, this dominance of open-shell systems prevails, although more than half of the originally enumerated radicals decomposed or rearranged upon geometry optimization. Importantly, these unstable cases were not included in the database. This choice was made because the definition of a chemical reaction requires the specification of the molecular topologies of educts and products (and how they are transformed). The full Rad-6 database is provided in the supporting information to this article.<fig id="Fig2"><label>Fig. 2</label><caption><title>The Rad-6 database.</title><p><bold>a</bold> Number of molecules in the database, according to their number of non-hydrogen atoms. <bold>b</bold> Structures of representative molecules in the database. Dots indicate radicals and respective SMILES strings are listed.</p></caption><graphic xlink:href="41467_2020_19267_Fig2_HTML" id="d30e466"/></fig></p><p id="Par10">Two central quantities that are needed to fully understand the overall kinetics of a reaction network are the RE (<italic>E</italic><sub>reac</sub>, RE) and the activation energy (barrier) for each reaction. Indeed, REs provide the most important features of the reaction network and can in some cases even be used to predict activation energies via the Br&#x000f8;nsted-Evans-Polanyi relation<sup><xref ref-type="bibr" rid="CR47">47</xref>&#x02013;<xref ref-type="bibr" rid="CR49">49</xref></sup>. Furthermore, while the activation energy is a property of each individual reaction (the edges in a graph), the RE can be computed from molecular atomization energies (<italic>E</italic><sub>at</sub>, AE), i.e. information from pairs of nodes in a graph, meaning that much fewer calculations are required to predict the REs in a large reaction network. Specifically, to predict 1000 REs for 20 molecules, one only needs 20 ground-state geometries. In contrast, predicting the corresponding activation energies would require 1000 additional transition state (TS) geometries. Not only are there more TS geometries, but these are also much harder to obtain, both in terms of computational effort and in terms of the human intervention needed for successful transition state searches. This makes predicting REs the logical first step in the ML-driven exploration of reaction networks.</p><p id="Par11">Specifically, for a reaction of the type:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A\,\longrightarrow\, B+C,$$\end{document}</tex-math><mml:math id="M2"><mml:mi>A</mml:mi><mml:mspace width="0.25em"/><mml:mo>&#x02192;</mml:mo><mml:mspace width="0.25em"/><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_19267_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>the REs can be computed from molecular atomization energies via:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{{\rm{reac}}}={E}_{{\rm{at}}}^{B}+{E}_{{\rm{at}}}^{C}-{E}_{{\rm{at}}}^{A},$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">reac</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">at</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">at</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">at</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_19267_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where we define the AE without loss of generality as the total energy of the molecule minus total energies of the isolated neutral atoms.</p><p id="Par12">Learning atomization energies across chemical compound space is a well-established practice in the ML literature. In a first approach, we can therefore apply such compound space models for predicting REs, as long as they are trained on a reactive database like Rad-6. Herein, we use Kernel Ridge Regression (KRR) with the SOAP<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> representation, as a state-of-the-art ML method (see SI for details). In brief, KRR uses a kernel function <italic>k</italic>(<italic>x</italic><sub><italic>i</italic></sub>,&#x000a0;<italic>x</italic><sub><italic>j</italic></sub>), to measure the similarity between representations <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub>. The herein used SOAP representation is one of a class of atom-density projections that have been found to yield highly accurate molecular ML models<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. With this type of model, the AE of an unknown molecule can be predicted according to its similarity with known molecules in a training set. Since the AE is a molecular property and SOAP is an atomic representation, an additional step is required for evaluating the similarity of molecules. This can, for example, be achieved with the average kernel<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{{\rm{int}}}(A,B)=\mathop{\sum }\limits_{a\in A,b\in B}\frac{1}{{N}_{A}\ {N}_{B}}k({x}_{a},{x}_{b}),$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">int</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.33em"/><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_19267_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <italic>N</italic><sub><italic>A</italic></sub> and <italic>N</italic><sub><italic>B</italic></sub> are the numbers of atoms <italic>a</italic> and <italic>b</italic> in molecules <italic>A</italic> and <italic>B</italic>, respectively, and <italic>x</italic><sub><italic>a</italic></sub> is the SOAP representation of the chemical environment of atom <italic>a</italic>. The lower-case <italic>k</italic> is used to differentiate the atomic from the molecular kernel function <italic>K</italic>. Alternatively, one can also use the sum kernel:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{{\rm{ext}}}(A,B)=\mathop{\sum }\limits_{a\in A,b\in B}k({x}_{a},{x}_{b}).$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ext</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_19267_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par13">Both average and sum kernels have been successfully used in ML models of the AE, but there is a crucial difference in their properties<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>: Specifically, the average kernel disregards size differences between molecules. It provides a measure for how similar the atoms in molecule <italic>A</italic> are to the ones in molecule <italic>B</italic>, on average. Meanwhile, the non-normalized sum kernel is sensitive to size differences. Consequently, models using the average kernel should be used to predict intensive quantities, and models using the sum kernel should predict extensive properties<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. Herein, all models using the average kernel are therefore trained on the atomization energy per atom (AE/<italic>N</italic>, an intensive quantity). The predicted AE/<italic>N</italic> is afterwards simply multiplied with the number of atoms <italic>N</italic> to recover the AE. Meanwhile, the sum kernel can directly be trained on (and predict) the AE<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. In the following we will refer to Eq. (<xref rid="Equ3" ref-type="">3</xref>) as the intensive kernel (<italic>K</italic><sub>int</sub>) and to Eq. (<xref rid="Equ4" ref-type="">4</xref>) as the extensive kernel (<italic>K</italic><sub>ext</sub>). As an aside, it should be noted that using such linear combination kernels is equivalent to the partitioning of the total energy inherent, for instance, to Gaussian Approximation Potentials<sup><xref ref-type="bibr" rid="CR29">29</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>.</p><p id="Par14">To train ML models, the Rad-6 database is split into training, validation (for hyperparameter optimization) and test sets. To obtain representative training sets, we use the farthest point sampling (FPS) method<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. In FPS, data-points are sequentially selected to maximize the distance between a new data-point (a molecule <italic>A</italic>) and all previously selected points (molecules <italic>B</italic> already in the training set). In the present context, this means new molecules added to the training set should be as dissimilar as possible to all previously selected molecules. The distance between molecules is measured using the previously introduced kernels, according to:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D(A,B)=\sqrt{K(A,A)+K(B,B)-2K(A,B)}.$$\end{document}</tex-math><mml:math id="M10"><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_19267_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>Because <italic>D</italic>(<italic>A</italic>,&#x000a0;<italic>B</italic>) depends on the kernel, we obtain different training sets for the intensive and extensive kernels. Most importantly, while we normalize <italic>K</italic><sub>int</sub> so that <italic>K</italic><sub>int</sub>(<italic>A</italic>,&#x000a0;<italic>A</italic>)&#x000a0;=&#x000a0;<italic>K</italic><sub>int</sub>(<italic>B</italic>,&#x000a0;<italic>B</italic>)&#x000a0;=&#x000a0;1, <italic>K</italic><sub>ext</sub> is not normalized. Consequently, <inline-formula id="IEq1"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{{\rm{ext}}}(A,A) \sim {N}_{A}^{2}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ext</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>~</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2020_19267_Article_IEq1.gif"/></alternatives></inline-formula> and <inline-formula id="IEq2"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{{\rm{ext}}}(B,B) \sim {N}_{B}^{2}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ext</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>~</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2020_19267_Article_IEq2.gif"/></alternatives></inline-formula>. This means that the distance <italic>D</italic><sub>ext</sub>(<italic>A</italic>,&#x000a0;<italic>B</italic>) evaluated with the extensive kernels tends to be greater between large systems than the distance between small systems. Accordingly, mostly large molecules are selected during the early iterations of FPS with <italic>D</italic><sub>ext</sub>, whereas the intensive distance <italic>D</italic><sub>int</sub> maximizes the average chemical diversity in the training set irrespective of size. It should be noted that a FPS selection based on maximally diverse atomic environments rather than molecules (e.g. using a softmax criterion<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>) would also be possible. This may be a better choice for datasets with large molecules.</p><p id="Par15">Beyond their use in regression methods like KRR, kernels can also be used for dimensionality reduction and visualization of large data sets with the kernel principal component analysis (kPCA) method<sup><xref ref-type="bibr" rid="CR55">55</xref>,<xref ref-type="bibr" rid="CR56">56</xref></sup>. In Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, kPCA plots of the Rad-6 chemical compound space for the intensive and extensive kernels are shown. Here, the two principal components mainly reflect the degree of saturation (the number of hydrogen atoms) and the oxygen/carbon ratio. The main difference in both projections is that the extensive kernel additionally displays a size-dependence, with small molecules (up to 4 heavy atoms) concentrated in the bottom right corner (see SI for more details).<fig id="Fig3"><label>Fig. 3</label><caption><title>Visualizing Rad-6 with Kernel Principal Component Analysis (kPCA).</title><p><bold>a</bold> kPCA based on an intensive kernel. <bold>b</bold> kPCA based on an extensive kernel. Points are colored according to the DFT atomization energy per atom in (<bold>a</bold>) and total atomization energy in (<bold>b</bold>). The arrows provide a qualitative interpretation of the principal component (PC) axes and small black dots indicate the FPS-selected training configurations for a ML model with 1000 training molecules and using the corresponding distance criterion (<italic>D</italic><sub>int</sub> (<bold>a</bold>), <italic>D</italic><sub>ext</sub> (<bold>b</bold>)), see text.</p></caption><graphic xlink:href="41467_2020_19267_Fig3_HTML" id="d30e1170"/></fig></p><p id="Par16">Superposed on the projected landscapes, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> shows the color-coded variation of the DFT computed AEs. A clear trend from more negative values in the top right to less negative values in the bottom left can be discerned for <italic>K</italic><sub>int</sub>. This correlation of AE/<italic>N</italic> with the degree of saturation results simply because highly saturated molecules contain only single bonds, while unsaturated molecules contain double and triple bonds. The gradual variation of both AE and AE/<italic>N</italic> also provides an intuitive understanding of why kernel models work for predicting molecular energies: Molecules that are close in the kPCA plot (i.e., considered to be similar by the kernel) also have a similar AE. Finally, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> also illustrates the distribution of the FPS-selected training points, which evenly cover the compound space, but also span most of the more isolated points at the bottom of the figure.</p></sec><sec id="Sec4"><title>Machine learning in compound space</title><p id="Par17">In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, the learning curves for AE predictions with the extensive and intensive kernels and using both <italic>D</italic><sub>ext</sub>-based and <italic>D</italic><sub>int</sub>-based FPS sets are shown, i.e., we also combine extensive kernel learning with intensive training sets and vice versa. It can be seen that with the largest training sets, all four models are able to predict atomization energies for these systems with mean absolute errors (MAEs) well below 0.1&#x02009;eV. In all cases, the log-log plots display the expected linear relationship (i.e., the learning curve can be fitted as a power law), indicating that even higher accuracy could be achieved with more data. To put this performance into perspective, it should be noted that our baseline method (dispersion-corrected hybrid DFT) itself has an average accuracy of ca. 4&#x02013;5&#x02009;&#x000a0;kcal&#x02009;mol<sup>&#x02212;1</sup> (0.2&#x02009;eV) for REs and barriers<sup><xref ref-type="bibr" rid="CR57">57</xref>,<xref ref-type="bibr" rid="CR58">58</xref></sup>.<fig id="Fig4"><label>Fig. 4</label><caption><title>Learning curves for atomization energies (AE).</title><p><bold>a</bold> Mean absolute error (MAE) of AE predictions on the test set, as a function of the number of training molecules <italic>n</italic><sub>train</sub>. The training sets were constructed using FPS with the extensive (<bold>a</bold>) and intensive kernels (<bold>b</bold>) (see text). <bold>c</bold> AE learning curves using molecular geometries obtained with the universal forcefield (UFF). The gray line represents a learning rate of <inline-formula id="IEq3"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{{\rm{train}}}^{0.65}$$\end{document}</tex-math><mml:math id="M16"><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">train</mml:mi></mml:mrow><mml:mrow><mml:mn>0.65</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2020_19267_Article_IEq3.gif"/></alternatives></inline-formula> and serves as a guide to the eye in all three panels.</p></caption><graphic xlink:href="41467_2020_19267_Fig4_HTML" id="d30e1264"/></fig></p><p id="Par18">Additional ML models were trained on randomly sampled training sets, to provide a baseline for the FPS schemes. The corresponding AE learning curves are comparable to the extensive FPS (see SI). As has previously been noted, random sampling is actually advantageous for very small training sets, but the learning rate is lower than for both FPS schemes translating into inferior performance for larger training sets<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>.</p><p id="Par19">Following common practice, all errors are shown for the total AE, even for the intensive models. Clearly, this is not a completely fair comparison, as the intensive models are trained to minimize the AE/<italic>N</italic> and not the total AE error. This explains the seemingly counter-intuitive fact that the extensive model performs better even on the intensive FPS training set. It has been suggested in the context of electronic structure methods that AE/<italic>N</italic> may generally be a more appropriate target for fitting and benchmarking<sup><xref ref-type="bibr" rid="CR58">58</xref>,<xref ref-type="bibr" rid="CR59">59</xref></sup>. Specifically, fitting on the total AE will selectively favor large systems over small ones, as they offer a larger potential for improvement in the loss function. This also carries over to the FPS selection, as extensive selection will initially focus on larger molecules which are deemed to be more dissimilar than smaller ones. We will see later that this has significant consequences for reaction networks and REs. Nevertheless, based on the data in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> one would deduce a slight superiority of the extensive kernel.</p><p id="Par20">Fully optimized DFT geometries will unfortunately not be available for ML training and prediction in a realistic application. If they were, the DFT energy would be known and the ML prediction would be redundant<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>. We therefore also used simple forcefield geometries (based on the universal forcefield, UFF)<sup><xref ref-type="bibr" rid="CR61">61</xref></sup> for training and prediction, still using the ground-state energies of relaxed DFT geometries as the target property. As shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>c and detailed in the SI, all trends discussed for the DFT geometries are unchanged, but the MAEs are somewhat higher, roughly by a factor of two. Such inferior performance of ML models using approximate geometries has also been observed for closed-shell data sets like QM9, but it is more pronounced here<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. This reflects the fact that general forcefields like UFF are not designed for the description of radicals, which make up a large part of Rad-6. In this context, semi-empirical electronic structure methods might offer an alternative low-cost method for more reliable geometries<sup><xref ref-type="bibr" rid="CR62">62</xref>,<xref ref-type="bibr" rid="CR63">63</xref></sup>. Note however that such methods will invariably afford some amount of rearrangement and decomposition upon geometry optimization, which would introduce a mismatch between the structure used to build the SOAP representation and the structure for which the target energies are computed. This could in principle be mitigated by using constrained relaxations, but defining universal geometrical constraints in a high-throughput setting is not trivial.</p><p id="Par21">It has also been shown that predictions from approximate geometries can be improved by using a measure of the quality of the training geometries to adjust the model regularization for each training sample<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. As shown in the SI, this is not successful for Rad-6. Again, we attribute this to the overall poor and inconsistent quality of the UFF geometries for open-shell systems, highlighting another challenge when moving towards ML approaches for reaction space.</p><p id="Par22">Nonetheless, even UFF-based models with fairly small training sets already provide a reasonable estimate of the AEs across chemical compound space. This is illustrated in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, where an interpolated AE/<italic>N</italic> surface for an ML model trained on 1000 UFF structures is compared to the DFT reference values. The plots are visually almost indistinguishable. This serves to emphasize that even a ML model trained on 10% of the database already provides an adequate representation of its overall thermochemistry. Recall that the core task for the development of rationally reduced reaction networks is not an excessive accuracy of this thermochemistry as typically targeted in existing ML work for compound space. Instead, the overall topology needs to be appropriately represented to a degree that enables the selection or dismissal of reactions when building sub-graphs.<fig id="Fig5"><label>Fig. 5</label><caption><title>Illustration of the Rad-6 chemical space as an interpolated height profile.</title><p><bold>a</bold> kPCA as in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> showing the DFT reference intensive atomization energies AE/<italic>N</italic> (in eV). <bold>b</bold> Prediction from the ML model using an intensive kernel and a small intensively selected training set of only 1000 molecules with UFF geometries. <bold>c</bold> Respective differences (DFT-ML). Here, the range of the colorbar is shifted but the scale is the same.</p></caption><graphic xlink:href="41467_2020_19267_Fig5_HTML" id="d30e1351"/></fig></p></sec><sec id="Sec5"><title>Machine learning in reaction space</title><p id="Par23">With the ML-predicted AEs, one can readily calculate REs using Eq. (<xref rid="Equ2" ref-type="">2</xref>), in strict analogy to how they are computed with first-principles methods. In this case, errors in the predicted AEs will propagate to the predicted REs. Under the most basic assumptions (i.e., an uncorrelated, constant uncertainty <italic>&#x003c3;</italic><sub><italic>A</italic><italic>E</italic></sub> for every AE prediction), one would expect the uncertainty in the RE prediction for a reaction <italic>A</italic>&#x02009;&#x027f6;&#x02009;<italic>B</italic>&#x02009;+&#x02009;<italic>C</italic> to be <inline-formula id="IEq4"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt{3}{\sigma }_{\mathrm{AE}}$$\end{document}</tex-math><mml:math id="M18"><mml:msqrt><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msqrt><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">AE</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_19267_Article_IEq4.gif"/></alternatives></inline-formula>. While this is a very rough estimate, it indicates that we would generally expect the error on REs to correlate with the AE error, and that the former should be larger than the latter.</p><p id="Par24">To test these expectations, a reaction network containing 32,515 bond-breaking reactions, Rad-6-RE, was generated using the Rad-6 molecules (see SI for details and the full dataset). In Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>, we show the relation between the performance of different ML models for AE and RE predictions, using both FPS training set selections (multiple points for each method correspond to the different training set sizes shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). These plots reveal several interesting trends. As expected, the RE error correlates with the AE error. However, there are significant differences both with respect to the FPS selection and the kernels. Most notably, all models display unexpectedly large errors for the smaller (<italic>N</italic>&#x02009;&#x02264;&#x02009;2000) extensive training sets. In contrast, the models trained on the intensive FPS display RE errors that are much closer to the corresponding AE errors. Strikingly, the combination of intensive kernel learning and intensive training set selection leads to RE errors that are almost identical to the corresponding AE errors across all training set sizes.<fig id="Fig6"><label>Fig. 6</label><caption><title>Correlation of mean absolute errors (MAE) for AE and RE prediction.</title><p><bold>a</bold> Correlation plot for the extensive FPS training set using the extensive and intensive kernels and DFT geometries. <bold>b</bold> Correlation plot for the intensive FPS training set using the extensive and intensive kernels and DFT geometries. Multiple points for each model represent the different training set sizes shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> (indicated in (<bold>b</bold>)), with smaller AE errors corresponding to larger training sets.</p></caption><graphic xlink:href="41467_2020_19267_Fig6_HTML" id="d30e1429"/></fig></p><p id="Par25">These observations can be understood in light of the fact that not all molecules are equally weighted in a reaction network. As can be seen in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, some molecules are central hubs in the network (dark green), whereas others lie on the periphery and only contribute to few reactions (white)<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup>. The existence of such hubs, which correspond to molecules with dramatically higher importance, is a fundamental difference between reaction space and the homogeneously weighted chemical compound space. In Rad-6-RE, the most important such hubs are small molecules that correspond to functional groups (OH, CH<sub>3</sub>, etc.) and the isolated atoms C, H and O. As mentioned previously, the extensive kernel distance <italic>D</italic><sub>ext</sub> will consider all smaller molecules to be more similar in terms of their kernel distance (Eq. (<xref rid="Equ5" ref-type="">5</xref>)), because the terms <italic>K</italic><sub>ext</sub>(<italic>A</italic>,&#x000a0;<italic>A</italic>) and <italic>K</italic><sub>ext</sub>(<italic>B</italic>,&#x000a0;<italic>B</italic>) scale with the number of atoms. Small molecules are therefore selected later in an extensive FPS selection, and are consequently absent from the smaller training sets. This can lead to relatively large errors on important hub molecules, which will consequently have an out-sized impact on the RE error.</p><p id="Par26">In other words, the large discrepancy between RE and AE for small extensive training sets is because small molecules are less likely to be included. This notion is further reinforced by considering the performance of the models based on random sampling. While the AE predictions of these models are of comparable accuracy with the FPS models (in particular for the smaller training sets), the performance for RE prediction is very poor, with MAEs above 1&#x02009;eV for small training sets (see SI). Even when the extensive kernel is trained on intensive sets, smaller molecules still offer less potential for improving the loss function and thus lead to a poorer performance for REs.</p><p id="Par27">In complete contrast to the situation in compound space, an intensive kernel with an intensively selected training set is therefore a better choice for ML models in reaction space. This indicates that some of the experience gathered hitherto for ML in chemical compound space (like the significant work on the QM9 database)<sup><xref ref-type="bibr" rid="CR34">34</xref>&#x02013;<xref ref-type="bibr" rid="CR36">36</xref></sup> will not necessarily carry over to reaction spaces. Realizing the particular relevance of hub molecules, a straightforward adaptation could for instance simply be to inversely scale the extensive distance used in the FPS selection by the degree of the node in the reaction network, i.e., by the number of reactions in which the molecule is involved (see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). Similarly, the least-squares problem for an extensive kernel could be adjusted by weighting the molecules according to their inverse size. With this work, we hope to initiate such dedicated methodological development for reaction spaces and will pursue corresponding research in the future.</p><p id="Par28">It should also be noted that the special topology of reaction networks makes model evaluation for REs in a strict statistical learning framework difficult. The reaction network Rad-6-RE contains most of the Rad-6 molecules. Computing the REs for this network is therefore not a pure prediction, as some molecules in each reaction may be in the training set. In principle, it would be desirable to evaluate the performance on a separate reaction network that contains no training molecules at all. However, this can only be achieved in two ways: Either the test network contains no small molecules like CO and OH, or these molecules are excluded from the training set. The former option leads to a very unnatural reaction network, that misses the most frequent classes of bond-breaking events. Meanwhile, the latter option leads to a very poor training set, and thus an overly pessimistic estimate of model performance.</p><p id="Par29">We therefore decided not to follow this strict separation of training and prediction for the RE MAEs shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. This also explains why the RE error is in some cases actually lower than the AE error, contrary to expectation: The RE MAE benefits from the fact that the prediction error of all tested models is somewhat lower on the training sets (see SI). Indeed, KRR models can in practice display a negligible error on the training set if the regularization parameter is chosen to be very small, as is advocated by some authors<sup><xref ref-type="bibr" rid="CR64">64</xref></sup>.</p></sec><sec id="Sec6"><title>Exploration of reaction networks</title><p id="Par30">Finally, we return to the original motivation of this work, namely the ML-aided exploration of complex reaction networks. To illustrate the use of ML-predicted REs, we consider a closed network of over 21,393 elementary reactions, containing a large variety of bond-breaking, transfer and rearrangement reactions for oxygen, carbon and hydrogen-containing molecules<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Note that this network is deliberately not a subset of Rad-6, although there is significant overlap (ca. 80% of the involved molecules are included in Rad-6). This is thus, at least partially, an out-of-sample application. The challenge lies in determining which of the elementary reactions are likely relevant to a chemical process of interest. As an exemplary process we consider the early stages of methane combustion<sup><xref ref-type="bibr" rid="CR65">65</xref>&#x02013;<xref ref-type="bibr" rid="CR69">69</xref></sup>.</p><p id="Par31">To validate the proposed ML models for this application, additional DFT calculations were performed on the out-of-sample systems. Unfortunately, these systems mostly decompose or rearrange upon DFT geometry optimization. Note that this does not necessarily mean that they are inherently unstable, however, just that the corresponding local minima were not found when starting from a (inaccurate) UFF geometry. We therefore used DFT single point calculations on UFF geometries here. Overall, a good correlation between DFT and ML-predicted energies is found, with systematically lower ML AEs (see SI). This systematic bias can easily be understood since the ML models predict the DFT energies of relaxed geometries, but the validation energies are for frozen UFF geometries. The latter is by definition larger than the former. This shows that the ML model can be used to estimate relaxed DFT energies even when these are not readily available from DFT calculations.</p><p id="Par32">To qualitatively explore this network, a mean-field microkinetic simulation of the reaction of equal parts CH<sub>4</sub> and O<sub>2</sub> was performed, assuming a constant activation barrier for all reactions (see SI for details). Under these assumptions, the reaction dynamics are only driven by the REs and the law of mass-action. While the true activation energies and detailed reaction conditions (initial concentrations, temperature, pressure, etc.) will obviously play a crucial role for the actual mechanism, such a simplified microkinetic simulation provides insight into how thermochemistry and the topology of the reaction network define which intermediates and reaction steps are at all relevant to the process. By observing how the reaction network grows with simulation time, we can furthermore understand how intermediates and reactions sequentially become available, as mass flows through different paths of the network. Only requiring ML-predicted REs as input, such a simulation is therefore a first step towards the envisioned rational reduction of the full network to tractable sub-graphs.</p><p id="Par33">&#x000a0; Figure&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref> summarizes the results obtained based on the intensive kernel ML model trained with an intensively selected FPS set of 9582 UFF structures. Shown are the reduced reaction networks extracted as those parts of the full network that are accessed at increasing simulation times. These reduced networks are highly revealing, as they form a hierarchy of different chemistries relevant to combustion. For example, in line with general expectations<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, the smallest network contains peroxide chemistry, with the hydrogen transfer from methane to molecular oxygen as the dominant pathway. Subsequently formed CO<sub><italic>y</italic></sub>H<sub><italic>x</italic></sub> intermediates also comprise generally anticipated molecules like methanol (CH<sub>3</sub>OH) or formic acid (HCOOH), but also more exotic species like the Criegee intermediate (CH<sub>2</sub>OO). Interestingly, the formation of the main product CO<sub>2</sub> only appears in larger subgraphs after dimerization reactions have already led to C<sub>2</sub> intermediates like ethylene (C<sub>2</sub>H<sub>4</sub>) and ethane (C<sub>2</sub>H<sub>6</sub>). Finally, the largest subgraphs shown include already more complex molecules like propane (C<sub>3</sub>H<sub>8</sub>) and propene (C<sub>3</sub>H<sub>6</sub>) and comprise a total of 887 reactions.<fig id="Fig7"><label>Fig. 7</label><caption><title>ML-based exploration of a complex reaction network.</title><p>Each frame shows the reduced reaction network extracted from a microkinetic simulation of methane combustion at different stages in simulation time. The abstract simulation time is shown for each frame in arbitrary units, see text. Educts and products (in bold), as well as important intermediates are highlighted. Nodes are colored according to their absolute atomization energies from low (red) to high (blue). Cyclic compounds are marked with an asterisk, to distinguish them from the corresponding linear compounds.</p></caption><graphic xlink:href="41467_2020_19267_Fig7_HTML" id="d30e1593"/></fig></p><p id="Par34">It should be emphasized that the networks in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref> are not intended to represent a definitive mechanism for methane combustion, not least because this mechanism strongly depends on reactions conditions like temperature, pressure and the methane/oxygen ratio<sup><xref ref-type="bibr" rid="CR68">68</xref></sup>. Instead, this analysis provides insight into what intermediates and elementary steps should be considered when constructing reduced reaction networks for mechanistic studies. While assuming constant barriers is clearly a harsh approximation in a microkinetic simulation, we note that predicting activation energies for the full network is not necessary to extract the relevant reduced reaction network for subsequent analysis. In many cases, an elementary reaction can be discarded because of a large thermochemical barrier alone. In other words, if a reaction is found to be irrelevant in a microkinetic simulation with constant barriers, it will not become relevant once activation barriers are included. Of course, activation barriers for the reduced network must still be computed for a quantitative microkinetic simulation, but this is only a small subset of the full network.</p><p id="Par35">Note also that a pure ML approach may miss important domain knowledge. For example, both singlet and triplet spin-states of CH<sub>2</sub> are relevant in combustion<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR68">68</xref></sup>. Instead, the graph-based enumeration approach<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> used to generate Rad-6, generically only considers the lowest-spin state of each molecule (with manually implemented exceptions of triplet O<sub>2</sub> and the isolated atoms to prevent completely unphysical results). Nonetheless, our pure ML approach finds all intermediates considered in empirical reduced methane combustion mechanism like the skeletal mechanism of Lu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR70">70</xref></sup>. On the other hand, the unbiased nature of ML approaches has the benefit of providing unexpected suggestions that would perhaps not be considered otherwise. For example, already our proof-of-concept reduced reaction networks of methane combustion suggest a pathway for CO<sub>2</sub> formation via the Criegee intermediate (CH<sub>2</sub>OO) and cyclic compounds like dioxirane (CH<sub>2</sub>OO*) that is not generally considered in state-of-the-art empirical networks. In our view, domain knowledge and ML-based exploration should therefore be combined in practice.</p><p id="Par36">Indeed, the generation of reference databases is also to an extent domain specific. The reaction networks considered herein are quite universal and could be applied to atmospheric chemistry, combustion or catalysis. However, these fields have distinct requirements with respect to the first-principles reference data. Clearly, catalysis can only be studied if the effect of the catalyst is accounted for. Meanwhile, thermal contributions to the free-energy will be large and important for a realistic description of combustion, and the role of different spin-states must be considered in both combustion and atmospheric chemistry. Nevertheless, the ML framework presented herein can easily be transferred to accommodate these situations.</p><p id="Par37">To demonstrate this, a second set of energies for Rad-6 was computed using broken-symmetry (BS) DFT (see SI for details). In BS-DFT, the DFT energy is further minimized by exploiting the breaking of spatial and spin-symmetry in the Kohn-Sham determinant. The resulting determinants consequently do not correspond to a predefined multiplicity but represent the lowest energy solution irrespective of the spin state. Importantly, we find that ML models trained on this data have very similar predictive accuracy to the ones discussed so far (see Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>). This shows that the Rad-6 database can serve as a benchmark for developing and improving ML models in reaction space, much like the popular QM9 set has done for chemical compound space.<fig id="Fig8"><label>Fig. 8</label><caption><title>Comparison ML models trained on the Rad-6 and the Rad-6-BS databases.</title><p><bold>a</bold> Learning curves for AE predictions of using the extensive kernel with an extensive FPS split and DFT geometries. <bold>b</bold> Same as (<bold>a</bold>) but for the intensive kernel with an intensive FPS split. <bold>c</bold> Correlation plot of MAE RE vs MAE AE for both Rad-6 and Rad-6-BS. Blue lines represent results obtained with the extensive kernel (crosses for Rad-6 and stars for Rad-6-BS) in (<bold>a</bold>) and (<bold>c</bold>). Red circles correspond to the intensive kernel with Rad-6 and orange diamonds to the intensive kernel with Rad-6-RE.</p></caption><graphic xlink:href="41467_2020_19267_Fig8_HTML" id="d30e1673"/></fig></p></sec></sec><sec id="Sec7" sec-type="discussion"><title>Discussion</title><p id="Par38">In this paper, we have explored the applicability of ML models to chemical reaction networks. In this context, we introduced the Rad-6 database of ca. 10,000 open and closed-shell molecules and an associated reaction network of ca. 30,000 reactions (Rad-6-RE). Established compound space KRR methods were shown to accurately predict atomization energies of the Rad-6 molecules. While the AE prediction accuracy was fairly similar for different choices in training set selection and kernel construction, these choices had a large effect on RE prediction accuracy. In particular, we found the use of an intensive kernel for both FPS-based training set selection and KRR learning to work very well for RE prediction, while models trained on extensive FPS sets displayed unexpectedly large RE errors. This can be rationalized by the special topology of reaction networks, in which certain small molecules constitute important hubs that should be included early on in the training sets.</p><p id="Par39">We note that the extensive and intensive kernels used herein are merely interesting representatives of a wider range of possible models. Fundamentally, the observed differences in performance between the AE and RE prediction reflect that not all concepts established for the ML-based exploration of chemical compound space can be carried over to reaction space. Multiple methodological developments are required to establish reliable protocols, for example with respect to the weighting of molecules in the loss function of the ML model. If the topology of the reaction network of interest is known, these weights could for example be selected according to the connectivity of the molecule in the network (as shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). Alternatively, weighting by size (or molecular weight) would likely be a useful heuristic to avoid the problems observed for the extensive kernel.</p><p id="Par40">We also presented a proof-of-principle application of a reactive ML model to the exploration of the methane combustion reaction network. Here, a microkinetic simulation based on ML energetics was carried out, revealing relevant pathways and elementary steps in a large reaction network of 21,000 reactions. In our view, there are two ways to proceed from here. On one hand, the relevant subgraph thus extracted from of a much larger reaction network could be studied in depth with first-principles methods. On the other hand, we can envision an ML-driven computational reactor, where this is done in a more integrated fashion. Important steps (as identified by an ML-driven microkinetic simulation) could be studied with DFT and the results used to retrain the ML model. This would lead to an active-learning-type iterative procedure, where the predicted energetics of the reaction network are continuously improved in a targeted fashion, and no subgraph selection is necessary (within the computational constraints of the microkinetic simulation).</p></sec><sec id="Sec8"><title>Methods</title><sec id="Sec9"><title>Computational details</title><p id="Par41">Reference geometries and energies were obtained using DFT as implemented in FHI-Aims<sup><xref ref-type="bibr" rid="CR46">46</xref>,<xref ref-type="bibr" rid="CR71">71</xref></sup>. Specifically, the PBE0 functional<sup><xref ref-type="bibr" rid="CR72">72</xref></sup> was used with tight integration settings and tier-2 numerical atomic orbital basis sets. Dispersion interactions were treated via the pair-wise Tkatchenko-Scheffler van-der-Waals correction<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>. Approximate geometries were obtained with the UFF forcefield<sup><xref ref-type="bibr" rid="CR61">61</xref></sup>.</p></sec><sec id="Sec10"><title>Machine-learning models</title><p id="Par42">All reported ML models are based on Kernel Ridge Regression and use the SOAP kernel<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR50">50</xref></sup>. SOAP representations were computed with the quippy code (<ext-link ext-link-type="uri" xlink:href="https://github.com/libAtoms/QUIP">https://github.com/libAtoms/QUIP</ext-link>). Kernel matrices and training/test splits were generated with the mltools package (<ext-link ext-link-type="uri" xlink:href="https://github.com/simonwengert/mltools.git">https://github.com/simonwengert/mltools.git</ext-link>). The atomic simulation environment was used throughout to process molecular data<sup><xref ref-type="bibr" rid="CR74">74</xref></sup>.</p><p id="Par43">Full methodological details are provided in the Supplementary information.</p></sec></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec11"><supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41467_2020_19267_MOESM1_ESM.pdf"><caption><p>Supplementary Information</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41467_2020_19267_MOESM2_ESM.pdf"><caption><p>Description of Additional Supplementary Files</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="41467_2020_19267_MOESM3_ESM.zip"><caption><p>Supplementary Data 1</p></caption></media></supplementary-material></sec></sec></body><back><fn-group><fn><p><bold>Peer review information</bold>
<italic>Nature Communications</italic> thanks Carl Simon Adorf, Jan Halborg Jensen and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p></fn><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p><bold>Supplementary information</bold> is available for this paper at 10.1038/s41467-020-19267-x.</p></sec><ack><title>Acknowledgements</title><p>This work was supported by the Deutsche Forschungsgemeinschaft (DFG) through TUM International Graduate School of Science and Engineering (IGSSE) (GSC 81) and by the TUM Institute for Advanced Study, which awarded a August-Wilhelm-Scheer visting professorship to G.C. We gratefully acknowledge S. Wengert for the technical support via mltools and for fruitful discussions.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>S.S. performed the DFT calculations on the Rad-6 database and fitted the ML models. J.T.M. performed the reaction network analysis and the BS-DFT calculations. G.C., K.R., and J.T.M. devised the project. All authors contributed to writing the manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open Access funding enabled and organized by Projekt DEAL.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All datasets used in this paper are available as Supplementary Data 1.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>The code used to fit the ML models is available at 10.5281/zenodo.4025972.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par44">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulissi</surname><given-names>ZW</given-names></name><name><surname>Medford</surname><given-names>AJ</given-names></name><name><surname>Bligaard</surname><given-names>T</given-names></name><name><surname>N&#x000f8;rskov</surname><given-names>JK</given-names></name></person-group><article-title>To address surface reaction network complexity using scaling relations machine learning and DFT calculations</article-title><source>Nat. Commun.</source><year>2017</year><volume>8</volume><fpage>14621</fpage><pub-id pub-id-type="doi">10.1038/ncomms14621</pub-id><?supplied-pmid 28262694?><pub-id pub-id-type="pmid">28262694</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gossler</surname><given-names>H</given-names></name><name><surname>Maier</surname><given-names>L</given-names></name><name><surname>Angeli</surname><given-names>S</given-names></name><name><surname>Tischer</surname><given-names>S</given-names></name><name><surname>Deutschmann</surname><given-names>O</given-names></name></person-group><article-title>CaRMeN: an improved computer-aided method for developing catalytic reaction mechanisms</article-title><source>Catalysts</source><year>2019</year><volume>9</volume><fpage>227</fpage><pub-id pub-id-type="doi">10.3390/catal9030227</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>H</given-names></name><name><surname>Kee</surname><given-names>RJ</given-names></name><name><surname>Janardhanan</surname><given-names>VM</given-names></name><name><surname>Deutschmann</surname><given-names>O</given-names></name><name><surname>Goodwin</surname><given-names>DG</given-names></name></person-group><article-title>Modeling elementary heterogeneous chemistry and electrochemistry in solid-oxide fuel cells</article-title><source>J. Electrochem. Soc.</source><year>2005</year><volume>152</volume><fpage>A2427</fpage><pub-id pub-id-type="doi">10.1149/1.2116607</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deutschmann</surname><given-names>O</given-names></name><name><surname>Schmidt</surname><given-names>LD</given-names></name></person-group><article-title>Modeling the partial oxidation of methane in a short-contact-time reactor</article-title><source>AIChE J.</source><year>1998</year><volume>44</volume><fpage>2465</fpage><lpage>2477</lpage><pub-id pub-id-type="doi">10.1002/aic.690441114</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harper</surname><given-names>MR</given-names></name><name><surname>Geem</surname><given-names>KMV</given-names></name><name><surname>Pyl</surname><given-names>SP</given-names></name><name><surname>Marin</surname><given-names>GB</given-names></name><name><surname>Green</surname><given-names>WH</given-names></name></person-group><article-title>Comprehensive reaction mechanism for n-butanol pyrolysis and combustion</article-title><source>Combust. Flame</source><year>2011</year><volume>158</volume><fpage>16</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.combustflame.2010.06.002</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sankaran</surname><given-names>R</given-names></name><name><surname>Hawkes</surname><given-names>ER</given-names></name><name><surname>Chen</surname><given-names>JH</given-names></name><name><surname>Lu</surname><given-names>T</given-names></name><name><surname>Law</surname><given-names>CK</given-names></name></person-group><article-title>Structure of a spatially developing turbulent lean methane-air bunsen flame</article-title><source>Proc. Combust. Inst.</source><year>2007</year><volume>31</volume><fpage>1291</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1016/j.proci.2006.08.025</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Smith, G. P. et al. Gri-mech 3.0. <ext-link ext-link-type="uri" xlink:href="http://www.me.berkeley.edu/gri_mech/">http://www.me.berkeley.edu/gri_mech/</ext-link>.</mixed-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinu</surname><given-names>R</given-names></name><name><surname>Broadbelt</surname><given-names>LJ</given-names></name></person-group><article-title>Unraveling reaction pathways and specifying reaction kinetics for complex systems</article-title><source>Annu. Rev. Chem. Biomol. Eng.</source><year>2012</year><volume>3</volume><fpage>29</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1146/annurev-chembioeng-062011-081108</pub-id><?supplied-pmid 22468596?><pub-id pub-id-type="pmid">22468596</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vereecken</surname><given-names>L</given-names></name><name><surname>Glowacki</surname><given-names>DR</given-names></name><name><surname>Pilling</surname><given-names>MJ</given-names></name></person-group><article-title>Theoretical chemical kinetics in tropospheric chemistry: methodologies and applications</article-title><source>Chem. Rev.</source><year>2015</year><volume>115</volume><fpage>4063</fpage><lpage>4114</lpage><pub-id pub-id-type="doi">10.1021/cr500488p</pub-id><?supplied-pmid 25843545?><pub-id pub-id-type="pmid">25843545</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashkenasy</surname><given-names>G</given-names></name><name><surname>Hermans</surname><given-names>TM</given-names></name><name><surname>Otto</surname><given-names>S</given-names></name><name><surname>Taylor</surname><given-names>AF</given-names></name></person-group><article-title>Systems chemistry</article-title><source>Chem. Soc. Rev.</source><year>2017</year><volume>46</volume><fpage>2543</fpage><lpage>2554</lpage><pub-id pub-id-type="doi">10.1039/C7CS00117G</pub-id><?supplied-pmid 28418049?><pub-id pub-id-type="pmid">28418049</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grzybowski</surname><given-names>BA</given-names></name><name><surname>Bishop</surname><given-names>KJM</given-names></name><name><surname>Kowalczyk</surname><given-names>B</given-names></name><name><surname>Wilmer</surname><given-names>CE</given-names></name></person-group><article-title>The &#x02018;wired&#x02019; universe of organic chemistry</article-title><source>Nat. Chem.</source><year>2009</year><volume>1</volume><fpage>31</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1038/nchem.136</pub-id><?supplied-pmid 21378798?><pub-id pub-id-type="pmid">21378798</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>W&#x000e4;chtersh&#x000e4;user</surname><given-names>G</given-names></name></person-group><article-title>Evolution of the first metabolic cycles</article-title><source>Proc. Natl Acad. Sci. USA</source><year>1990</year><volume>87</volume><fpage>200</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1073/pnas.87.1.200</pub-id><?supplied-pmid 2296579?><pub-id pub-id-type="pmid">2296579</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simm</surname><given-names>GN</given-names></name><name><surname>Reiher</surname><given-names>M</given-names></name></person-group><article-title>Systematic error estimation for chemical reaction energies</article-title><source>J. Chem. Theory Comput.</source><year>2016</year><volume>12</volume><fpage>2762</fpage><lpage>2773</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.6b00318</pub-id><?supplied-pmid 27159007?><pub-id pub-id-type="pmid">27159007</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kowalik</surname><given-names>M</given-names></name><etal/></person-group><article-title>Parallel optimization of synthetic pathways within the network of organic chemistry</article-title><source>Angew. Chem. Int. Ed.</source><year>2012</year><volume>51</volume><fpage>7928</fpage><lpage>7932</lpage><pub-id pub-id-type="doi">10.1002/anie.201202209</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bajczyk</surname><given-names>MD</given-names></name><name><surname>Dittwald</surname><given-names>P</given-names></name><name><surname>Wo&#x00142;os</surname><given-names>A</given-names></name><name><surname>Szymku&#x00107;</surname><given-names>S</given-names></name><name><surname>Grzybowski</surname><given-names>BA</given-names></name></person-group><article-title>Discovery and enumeration of organic-chemical and biomimetic reaction cycles within the network of chemistry</article-title><source>Angew. Chem. Int. Ed.</source><year>2018</year><volume>57</volume><fpage>2367</fpage><lpage>2371</lpage><pub-id pub-id-type="doi">10.1002/anie.201712052</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>KJM</given-names></name><name><surname>Klajn</surname><given-names>R</given-names></name><name><surname>Grzybowski</surname><given-names>BA</given-names></name></person-group><article-title>The core and most useful molecules in organic chemistry</article-title><source>Angew. Chem. Int. Ed.</source><year>2006</year><volume>45</volume><fpage>5348</fpage><lpage>5354</lpage><pub-id pub-id-type="doi">10.1002/anie.200600881</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fialkowski</surname><given-names>M</given-names></name><name><surname>Bishop</surname><given-names>KJM</given-names></name><name><surname>Chubukov</surname><given-names>VA</given-names></name><name><surname>Campbell</surname><given-names>CJ</given-names></name><name><surname>Grzybowski</surname><given-names>BA</given-names></name></person-group><article-title>Architecture and evolution of organic chemistry</article-title><source>Angew. Chem. Int. Ed.</source><year>2005</year><volume>44</volume><fpage>7263</fpage><lpage>7269</lpage><pub-id pub-id-type="doi">10.1002/anie.200502272</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simm</surname><given-names>GN</given-names></name><name><surname>Reiher</surname><given-names>M</given-names></name></person-group><article-title>Context-driven exploration of complex chemical reaction networks</article-title><source>J. Chem. Theory Comput.</source><year>2017</year><volume>13</volume><fpage>6108</fpage><lpage>6119</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.7b00945</pub-id><?supplied-pmid 29084387?><pub-id pub-id-type="pmid">29084387</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacob</surname><given-names>P-M</given-names></name><name><surname>Lapkin</surname><given-names>A</given-names></name></person-group><article-title>Statistics of the network of organic chemistry</article-title><source>React. Chem. Eng.</source><year>2018</year><volume>3</volume><fpage>102</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1039/C7RE00129K</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>Y</given-names></name><name><surname>Kim</surname><given-names>JW</given-names></name><name><surname>Kim</surname><given-names>Z</given-names></name><name><surname>Kim</surname><given-names>WY</given-names></name></person-group><article-title>Efficient prediction of reaction paths through molecular graph and reaction network analysis</article-title><source>Chem. Sci.</source><year>2018</year><volume>9</volume><fpage>825</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1039/C7SC03628K</pub-id><?supplied-pmid 29675146?><pub-id pub-id-type="pmid">29675146</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simm</surname><given-names>GN</given-names></name><name><surname>Vaucher</surname><given-names>AC</given-names></name><name><surname>Reiher</surname><given-names>M</given-names></name></person-group><article-title>Exploration of reaction pathways and chemical transformation networks</article-title><source>J. Phys. Chem. A</source><year>2019</year><volume>123</volume><fpage>385</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1021/acs.jpca.8b10007</pub-id><?supplied-pmid 30421924?><pub-id pub-id-type="pmid">30421924</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margraf</surname><given-names>JT</given-names></name><name><surname>Reuter</surname><given-names>K</given-names></name></person-group><article-title>Systematic enumeration of elementary reaction steps in surface catalysis</article-title><source>ACS Omega</source><year>2019</year><volume>4</volume><fpage>3370</fpage><lpage>3379</lpage><pub-id pub-id-type="doi">10.1021/acsomega.8b03200</pub-id><?supplied-pmid 31459551?><pub-id pub-id-type="pmid">31459551</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruix</surname><given-names>A</given-names></name><name><surname>Margraf</surname><given-names>JT</given-names></name><name><surname>Andersen</surname><given-names>M</given-names></name><name><surname>Reuter</surname><given-names>K</given-names></name></person-group><article-title>First-principles-based multiscale modelling of heterogeneous catalysis</article-title><source>Nat. Catal.</source><year>2019</year><volume>2</volume><fpage>659</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/s41929-019-0298-3</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>N</given-names></name><etal/></person-group><article-title>Intrinsic selectivity and structure sensitivity of rhodium catalysts for C<sub>2+</sub> oxygenate production</article-title><source>J. Am. Chem. Soc.</source><year>2016</year><volume>138</volume><fpage>3705</fpage><lpage>3714</lpage><pub-id pub-id-type="doi">10.1021/jacs.5b12087</pub-id><?supplied-pmid 26958997?><pub-id pub-id-type="pmid">26958997</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medford</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>Activity and selectivity trends in synthesis gas conversion to higher alcohols</article-title><source>Top. Catal.</source><year>2014</year><volume>57</volume><fpage>135</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1007/s11244-013-0169-0</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>Z</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Mao</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>P</given-names></name></person-group><article-title>Quantitative determination of C-C coupling mechanisms and detailed analyses on the activity and selectivity for Fischer-Tropsch synthesis on Co(0001): microkinetic modeling with coverage effects</article-title><source>ACS Catal.</source><year>2019</year><volume>9</volume><fpage>5957</fpage><lpage>5973</lpage><pub-id pub-id-type="doi">10.1021/acscatal.9b01150</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rupp</surname><given-names>M</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K-R</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title>Fast and accurate modeling of molecular atomization energies with machine learning</article-title><source>Phys. Rev. Lett.</source><year>2012</year><volume>108</volume><fpage>058301</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.108.058301</pub-id><?supplied-pmid 22400967?><pub-id pub-id-type="pmid">22400967</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title>Quantum machine learning in chemical compound space</article-title><source>Angew. Chem. Int. Ed.</source><year>2018</year><volume>57</volume><fpage>4164</fpage><lpage>4169</lpage><pub-id pub-id-type="doi">10.1002/anie.201709686</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bart&#x000f3;k</surname><given-names>AP</given-names></name><name><surname>Payne</surname><given-names>MC</given-names></name><name><surname>Kondor</surname><given-names>R</given-names></name><name><surname>Cs&#x000e1;nyi</surname><given-names>G</given-names></name></person-group><article-title>Gaussian approximation potentials: the accuracy of quantum mechanics, without the electrons</article-title><source>Phys. Rev. Lett.</source><year>2010</year><volume>104</volume><fpage>136403</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.104.136403</pub-id><?supplied-pmid 20481899?><pub-id pub-id-type="pmid">20481899</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behler</surname><given-names>J</given-names></name></person-group><article-title>Atom-centered symmetry functions for constructing high-dimensional neural network potentials</article-title><source>J. Chem. Phys.</source><year>2011</year><volume>134</volume><fpage>074106</fpage><pub-id pub-id-type="doi">10.1063/1.3553717</pub-id><?supplied-pmid 21341827?><pub-id pub-id-type="pmid">21341827</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>K</given-names></name><etal/></person-group><article-title>Assessment and Validation of Machine Learning Methods for Predicting Molecular Atomization Energies</article-title><source>J. Chem. Theory Comput.</source><year>2013</year><volume>9</volume><fpage>3404</fpage><lpage>3419</lpage><pub-id pub-id-type="doi">10.1021/ct400195d</pub-id><?supplied-pmid 26584096?><pub-id pub-id-type="pmid">26584096</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stuke</surname><given-names>A</given-names></name><etal/></person-group><article-title>Chemical diversity in molecular orbital energy predictions with kernel ridge regression</article-title><source>J. Chem. Phys.</source><year>2019</year><volume>150</volume><fpage>204121</fpage><pub-id pub-id-type="doi">10.1063/1.5086105</pub-id><?supplied-pmid 31153160?><pub-id pub-id-type="pmid">31153160</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>H&#x000e4;se</surname><given-names>F</given-names></name><name><surname>Valleau</surname><given-names>S</given-names></name><name><surname>Pyzer-Knapp</surname><given-names>E</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A</given-names></name></person-group><article-title>Machine learning exciton dynamics</article-title><source>Chem. Sci.</source><year>2016</year><volume>7</volume><fpage>5139</fpage><lpage>5147</lpage><pub-id pub-id-type="doi">10.1039/C5SC04786B</pub-id><?supplied-pmid 30155164?><pub-id pub-id-type="pmid">30155164</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faber</surname><given-names>FA</given-names></name><name><surname>Christensen</surname><given-names>AS</given-names></name><name><surname>Huang</surname><given-names>B</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title>Alchemical and structural distribution based representation for universal quantum machine learning</article-title><source>J. Chem. Phys.</source><year>2018</year><volume>148</volume><fpage>241717</fpage><pub-id pub-id-type="doi">10.1063/1.5020710</pub-id><?supplied-pmid 29960351?><pub-id pub-id-type="pmid">29960351</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Huo, H. &#x00026; Rupp, M. Unified representation of molecules and crystals for machine learning. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2006.11223">https://arxiv.org/abs/2006.11223</ext-link>.</mixed-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bart&#x000f3;k</surname><given-names>AP</given-names></name><etal/></person-group><article-title>Machine learning unifies the modeling of materials and molecules</article-title><source>Sci. Adv.</source><year>2017</year><volume>3</volume><fpage>e1701816</fpage><pub-id pub-id-type="doi">10.1126/sciadv.1701816</pub-id><?supplied-pmid 29242828?><pub-id pub-id-type="pmid">29242828</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De</surname><given-names>S</given-names></name><name><surname>Bart&#x000f3;k</surname><given-names>AP</given-names></name><name><surname>Cs&#x000e1;nyi</surname><given-names>G</given-names></name><name><surname>Ceriotti</surname><given-names>M</given-names></name></person-group><article-title>Comparing molecules and solids across structural and alchemical space</article-title><source>Phys. Chem. Chem. Phys.</source><year>2016</year><volume>18</volume><fpage>13754</fpage><lpage>13769</lpage><pub-id pub-id-type="doi">10.1039/C6CP00415F</pub-id><?supplied-pmid 27101873?><pub-id pub-id-type="pmid">27101873</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stuke</surname><given-names>A</given-names></name><etal/></person-group><article-title>Atomic structures and orbital energies of 61,489 crystal-forming organic molecules</article-title><source>Sci. Data</source><year>2020</year><volume>7</volume><fpage>58</fpage><pub-id pub-id-type="doi">10.1038/s41597-020-0385-y</pub-id><?supplied-pmid 32071311?><pub-id pub-id-type="pmid">32071311</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unke</surname><given-names>OT</given-names></name><name><surname>Meuwly</surname><given-names>M</given-names></name></person-group><article-title>PhysNet: a neural network for predicting energies, forces, dipole moments, and partial charges</article-title><source>J. Chem. Theory Comput.</source><year>2019</year><volume>15</volume><fpage>3678</fpage><lpage>3693</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.9b00181</pub-id><?supplied-pmid 31042390?><pub-id pub-id-type="pmid">31042390</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000fc;tt</surname><given-names>KT</given-names></name><etal/></person-group><article-title>SchNetPack: a deep learning toolbox for atomistic systems</article-title><source>J. Chem. Theory Comput.</source><year>2019</year><volume>15</volume><fpage>448</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.8b00908</pub-id><?supplied-pmid 30481453?><pub-id pub-id-type="pmid">30481453</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>JS</given-names></name><name><surname>Isayev</surname><given-names>O</given-names></name><name><surname>Roitberg</surname><given-names>AE</given-names></name></person-group><article-title>ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost</article-title><source>Chem. Sci.</source><year>2017</year><volume>8</volume><fpage>3192</fpage><lpage>3203</lpage><pub-id pub-id-type="doi">10.1039/C6SC05720A</pub-id><?supplied-pmid 28507695?><pub-id pub-id-type="pmid">28507695</pub-id></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruddigkeit</surname><given-names>L</given-names></name><name><surname>Van Deursen</surname><given-names>R</given-names></name><name><surname>Blum</surname><given-names>LC</given-names></name><name><surname>Reymond</surname><given-names>JL</given-names></name></person-group><article-title>Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17</article-title><source>J. Chem. Inf. Model.</source><year>2012</year><volume>52</volume><fpage>2864</fpage><lpage>2875</lpage><pub-id pub-id-type="doi">10.1021/ci300415d</pub-id><?supplied-pmid 23088335?><pub-id pub-id-type="pmid">23088335</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramakrishnan</surname><given-names>R</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title>Many molecular properties from one kernel in chemical space</article-title><source>Chim. Int. J. Chem.</source><year>2015</year><volume>69</volume><fpage>182</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.2533/chimia.2015.182</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perdew</surname><given-names>JP</given-names></name><name><surname>Ernzerhof</surname><given-names>M</given-names></name><name><surname>Burke</surname><given-names>K</given-names></name></person-group><article-title>Rationale for mixing exact exchange with density functional approximations</article-title><source>J. Chem. Phys.</source><year>1996</year><volume>105</volume><fpage>9982</fpage><lpage>9985</lpage><pub-id pub-id-type="doi">10.1063/1.472933</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkatchenko</surname><given-names>A</given-names></name><name><surname>Scheffler</surname><given-names>M</given-names></name></person-group><article-title>Accurate Molecular Van Der Waals Interactions from Ground-State Electron Density and Free-Atom Reference Data</article-title><source>Phys. Rev. Lett.</source><year>2009</year><volume>102</volume><fpage>073005</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.102.073005</pub-id><?supplied-pmid 19257665?><pub-id pub-id-type="pmid">19257665</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blum</surname><given-names>V</given-names></name><etal/></person-group><article-title>Ab initio molecular simulations with numeric atom-centered orbitals</article-title><source>Comput. Phys. Commun.</source><year>2009</year><volume>180</volume><fpage>2175</fpage><lpage>2196</lpage><pub-id pub-id-type="doi">10.1016/j.cpc.2009.06.022</pub-id></element-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtarolo</surname><given-names>S</given-names></name><etal/></person-group><article-title>The high-throughput highway to computational materials design</article-title><source>Nat. Mater.</source><year>2013</year><volume>12</volume><fpage>191</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1038/nmat3568</pub-id><?supplied-pmid 23422720?><pub-id pub-id-type="pmid">23422720</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>M</given-names></name><name><surname>Levchenko</surname><given-names>SV</given-names></name><name><surname>Scheffler</surname><given-names>M</given-names></name><name><surname>Reuter</surname><given-names>K</given-names></name></person-group><article-title>Beyond scaling relations for the description of catalytic materials</article-title><source>ACS Catal.</source><year>2019</year><volume>9</volume><fpage>2752</fpage><lpage>2759</lpage><pub-id pub-id-type="doi">10.1021/acscatal.8b04478</pub-id></element-citation></ref><ref id="CR49"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>G</given-names></name><name><surname>Bligaard</surname><given-names>T</given-names></name><name><surname>Abild-Pedersen</surname><given-names>F</given-names></name><name><surname>N&#x000f8;rskov</surname><given-names>JK</given-names></name></person-group><article-title>Using scaling relations to understand trends in the catalytic activity of transition metals</article-title><source>J. Phys. Condens. Matter</source><year>2008</year><volume>20</volume><fpage>064239</fpage><pub-id pub-id-type="doi">10.1088/0953-8984/20/6/064239</pub-id><?supplied-pmid 21693900?><pub-id pub-id-type="pmid">21693900</pub-id></element-citation></ref><ref id="CR50"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bart&#x000f3;k</surname><given-names>AP</given-names></name><name><surname>Kondor</surname><given-names>R</given-names></name><name><surname>Cs&#x000e1;nyi</surname><given-names>G</given-names></name></person-group><article-title>On representing chemical environments</article-title><source>Phys. Rev. B</source><year>2013</year><volume>87</volume><fpage>184115</fpage><pub-id pub-id-type="doi">10.1103/PhysRevB.87.184115</pub-id></element-citation></ref><ref id="CR51"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willatt</surname><given-names>MJ</given-names></name><name><surname>Musil</surname><given-names>F</given-names></name><name><surname>Ceriotti</surname><given-names>M</given-names></name></person-group><article-title>Atom-density representations for machine learning</article-title><source>J. Chem. Phys.</source><year>2019</year><volume>150</volume><fpage>154110</fpage><pub-id pub-id-type="doi">10.1063/1.5090481</pub-id><?supplied-pmid 31005079?><pub-id pub-id-type="pmid">31005079</pub-id></element-citation></ref><ref id="CR52"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuo</surname><given-names>Y</given-names></name><etal/></person-group><article-title>A performance and cost assessment of machine learning interatomic potentials</article-title><source>J. Phys. Chem. A</source><year>2019</year><volume>124</volume><fpage>731</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1021/acs.jpca.9b08723</pub-id></element-citation></ref><ref id="CR53"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>H</given-names></name><etal/></person-group><article-title>Size-extensive molecular machine learning with global representations</article-title><source>ChemSystemsChem</source><year>2020</year><volume>2</volume><fpage>e1900052</fpage><pub-id pub-id-type="doi">10.1002/syst.201900052</pub-id></element-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Bishop, C. <italic>Pattern Recognition and Machine Learning</italic> (Springer, 2006).</mixed-citation></ref><ref id="CR55"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K-R</given-names></name></person-group><article-title>Nonlinear component analysis as a kernel eigenvalue problem</article-title><source>Neural Comput.</source><year>1998</year><volume>10</volume><fpage>1299</fpage><lpage>1319</lpage><pub-id pub-id-type="doi">10.1162/089976698300017467</pub-id></element-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">Cheng, B. et al. Mapping materials and molecules. <italic>Acc. Chem. Res</italic>. accepted (2020).</mixed-citation></ref><ref id="CR57"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goerigk</surname><given-names>L</given-names></name><etal/></person-group><article-title>A look at the density functional theory zoo with the advanced GMTKN55 database for general main group thermochemistry, kinetics and noncovalent interactions</article-title><source>Phys. Chem. Chem. Phys.</source><year>2017</year><volume>19</volume><fpage>32184</fpage><lpage>32215</lpage><pub-id pub-id-type="doi">10.1039/C7CP04913G</pub-id><?supplied-pmid 29110012?><pub-id pub-id-type="pmid">29110012</pub-id></element-citation></ref><ref id="CR58"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margraf</surname><given-names>JT</given-names></name><name><surname>Ranasinghe</surname><given-names>DS</given-names></name><name><surname>Bartlett</surname><given-names>RJ</given-names></name></person-group><article-title>Automatic generation of reaction energy databases from highly accurate atomization energy benchmark sets</article-title><source>Phys. Chem. Chem. Phys.</source><year>2017</year><volume>19</volume><fpage>9798</fpage><lpage>9805</lpage><pub-id pub-id-type="doi">10.1039/C7CP00757D</pub-id><?supplied-pmid 28361143?><pub-id pub-id-type="pmid">28361143</pub-id></element-citation></ref><ref id="CR59"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perdew</surname><given-names>JP</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Garza</surname><given-names>AJ</given-names></name><name><surname>Scuseria</surname><given-names>GE</given-names></name></person-group><article-title>Intensive atomization energy: re-thinking a metric for electronic structure theory methods</article-title><source>Z. Phys. Chem.</source><year>2016</year><volume>230</volume><fpage>737</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1515/zpch-2015-0713</pub-id></element-citation></ref><ref id="CR60"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rupp</surname><given-names>M</given-names></name></person-group><article-title>Machine learning for quantum mechanics in a nutshell</article-title><source>Int. J. Quantum Chem.</source><year>2015</year><volume>115</volume><fpage>1058</fpage><lpage>1073</lpage><pub-id pub-id-type="doi">10.1002/qua.24954</pub-id></element-citation></ref><ref id="CR61"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rappe</surname><given-names>AK</given-names></name><name><surname>Casewit</surname><given-names>CJ</given-names></name><name><surname>Colwell</surname><given-names>KS</given-names></name><name><surname>Goddard</surname><given-names>WA</given-names></name><name><surname>Skiff</surname><given-names>WM</given-names></name></person-group><article-title>UFF, a full periodic table force field for molecular mechanics and molecular dynamics simulations</article-title><source>J. Am. Chem. Soc.</source><year>1992</year><volume>114</volume><fpage>10024</fpage><lpage>10035</lpage><pub-id pub-id-type="doi">10.1021/ja00051a040</pub-id></element-citation></ref><ref id="CR62"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimme</surname><given-names>S</given-names></name><name><surname>Bannwarth</surname><given-names>C</given-names></name><name><surname>Shushkov</surname><given-names>P</given-names></name></person-group><article-title>A robust and accurate tight-binding quantum chemical method for structures, vibrational frequencies, and noncovalent interactions of large molecular systems parametrized for all spd-block elements (Z = 1-86)</article-title><source>J. Chem. Theory Comput.</source><year>2017</year><volume>13</volume><fpage>1989</fpage><lpage>2009</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.7b00118</pub-id><?supplied-pmid 28418654?><pub-id pub-id-type="pmid">28418654</pub-id></element-citation></ref><ref id="CR63"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaus</surname><given-names>M</given-names></name><name><surname>Goez</surname><given-names>A</given-names></name><name><surname>Elstner</surname><given-names>M</given-names></name></person-group><article-title>Parametrization and benchmark of DFTB3 for organic molecules</article-title><source>J. Chem. Theory Comput.</source><year>2013</year><volume>9</volume><fpage>338</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1021/ct300849w</pub-id><?supplied-pmid 26589037?><pub-id pub-id-type="pmid">26589037</pub-id></element-citation></ref><ref id="CR64"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mezei</surname><given-names>PD</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title>Noncovalent quantum machine learning corrections to density functionals</article-title><source>J. Chem. Theory Comput.</source><year>2020</year><volume>16</volume><fpage>2647</fpage><lpage>2653</lpage><pub-id pub-id-type="doi">10.1021/acs.jctc.0c00181</pub-id><?supplied-pmid 32130000?><pub-id pub-id-type="pmid">32130000</pub-id></element-citation></ref><ref id="CR65"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagheri</surname><given-names>G</given-names></name><etal/></person-group><article-title>Comprehensive kinetic study of combustion technologies for low environmental impact: MILD and OXY-fuel combustion of methane</article-title><source>Combust. Flame</source><year>2020</year><volume>212</volume><fpage>142</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1016/j.combustflame.2019.10.014</pub-id></element-citation></ref><ref id="CR66"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Onda</surname><given-names>T</given-names></name><name><surname>Nakamura</surname><given-names>H</given-names></name><name><surname>Tezuka</surname><given-names>T</given-names></name><name><surname>Hasegawa</surname><given-names>S</given-names></name><name><surname>Maruta</surname><given-names>K</given-names></name></person-group><article-title>Initial-stage reaction of methane examined by optical measurements of weak flames in a micro flow reactor with a controlled temperature profile</article-title><source>Combust. Flame</source><year>2019</year><volume>206</volume><fpage>292</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1016/j.combustflame.2019.04.044</pub-id></element-citation></ref><ref id="CR67"><label>67.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>F</given-names></name><etal/></person-group><article-title>Global reaction mechanisms for MILD oxy-combustion of methane</article-title><source>Energy</source><year>2018</year><volume>147</volume><fpage>839</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2018.01.089</pub-id></element-citation></ref><ref id="CR68"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>T-C</given-names></name><etal/></person-group><article-title>Modeling of aromatics formation in fuel-rich methane oxy-combustion with an automatically generated pressure-dependent mechanism</article-title><source>Phys. Chem. Chem. Phys.</source><year>2019</year><volume>21</volume><fpage>813</fpage><lpage>832</lpage><pub-id pub-id-type="doi">10.1039/C8CP06097E</pub-id><?supplied-pmid 30556072?><pub-id pub-id-type="pmid">30556072</pub-id></element-citation></ref><ref id="CR69"><label>69.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Mi</surname><given-names>J</given-names></name></person-group><article-title>Optimization of the global reaction mechanism for MILD combustion of methane using artificial neural network</article-title><source>Energy Fuels</source><year>2020</year><volume>34</volume><fpage>3805</fpage><lpage>3815</lpage><pub-id pub-id-type="doi">10.1021/acs.energyfuels.9b04413</pub-id></element-citation></ref><ref id="CR70"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laguillo</surname><given-names>S</given-names></name><name><surname>Ochoa</surname><given-names>JS</given-names></name><name><surname>Ortiz</surname><given-names>A</given-names></name></person-group><article-title>Chemical reaction mechanisms assessment for simulation of methane combustion in domestic gas cooking burners</article-title><source>Energy Fuels</source><year>2019</year><volume>33</volume><fpage>9171</fpage><lpage>9183</lpage><pub-id pub-id-type="doi">10.1021/acs.energyfuels.9b01598</pub-id></element-citation></ref><ref id="CR71"><label>71.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>IY</given-names></name><name><surname>Ren</surname><given-names>X</given-names></name><name><surname>Rinke</surname><given-names>P</given-names></name><name><surname>Blum</surname><given-names>V</given-names></name><name><surname>Scheffler</surname><given-names>M</given-names></name></person-group><article-title>Numeric atom-centered-orbital basis sets with valence-correlation consistency from H to Ar</article-title><source>N. J. Phys.</source><year>2013</year><volume>15</volume><fpage>123033</fpage><pub-id pub-id-type="doi">10.1088/1367-2630/15/12/123033</pub-id></element-citation></ref><ref id="CR72"><label>72.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adamo</surname><given-names>C</given-names></name><name><surname>Barone</surname><given-names>V</given-names></name></person-group><article-title>Towards reliable density functional methods without adjustable parameters: the PBE0 model</article-title><source>J. Chem. Phys.</source><year>1999</year><volume>110</volume><fpage>6158</fpage><lpage>6170</lpage><pub-id pub-id-type="doi">10.1063/1.478522</pub-id></element-citation></ref><ref id="CR73"><label>73.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkatchenko</surname><given-names>A</given-names></name><name><surname>DiStasio</surname><given-names>RA</given-names></name><name><surname>Car</surname><given-names>R</given-names></name><name><surname>Scheffler</surname><given-names>M</given-names></name></person-group><article-title>Accurate and efficient method for many-body van der waals interactions</article-title><source>Phys. Rev. Lett.</source><year>2012</year><volume>108</volume><fpage>236402</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.108.236402</pub-id><?supplied-pmid 23003978?><pub-id pub-id-type="pmid">23003978</pub-id></element-citation></ref><ref id="CR74"><label>74.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hjorth Larsen</surname><given-names>A</given-names></name><etal/></person-group><article-title>The atomic simulation environment-a Python library for working with atoms</article-title><source>J. Phys. Condens. Matter</source><year>2017</year><volume>29</volume><fpage>273002</fpage><pub-id pub-id-type="doi">10.1088/1361-648X/aa680e</pub-id><?supplied-pmid 28323250?><pub-id pub-id-type="pmid">28323250</pub-id></element-citation></ref></ref-list></back></article>