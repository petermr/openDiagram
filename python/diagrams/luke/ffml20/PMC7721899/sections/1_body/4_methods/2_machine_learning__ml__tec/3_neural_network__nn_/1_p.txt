0: Neural network is a mathematical model which maps a given set of predictors,  \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$x$$\end{document}x, to a set of desired response,  \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$y$$\end{document}y.
1: The early proposition of this idea is linked to the assumption of how the information is stored and processed in the brain 53.
2: The map between the predictor and the response is comprised of multiple layers of perceptron and activation functions and it is called the feed-forward neural network.
3: The estimated response can be expressed as follows, 9\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\varvec{y}} = {\varvec{f}}_{{\varvec{N}}} \left( {{\varvec{A}}_{{\varvec{N}}} , \ldots {\varvec{f}}_{2} \left( {{\varvec{A}}_{2} ,{\varvec{f}}_{1} \left( {{\varvec{A}}_{1} ,{\varvec{x}}} \right)} \right) \ldots } \right) $$\end{document}y=fNAN,...f2A2,f1A1,x...where  \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$${\varvec{f}}_{{\varvec{N}}} \left( \cdot \right):{\mathbb{R}} \to {\mathbb{R}}$$\end{document}fN:RR is a continuous bounded function which is usually referred to as the activation function,  \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$${\varvec{A}}_{{\varvec{i}}} :{\mathbb{R}}^{{{\varvec{d}}_{{\varvec{i}}} }} \to {\mathbb{R}}^{{{\varvec{d}}_{{{\varvec{i}} + 1}} }}$$\end{document}Ai:RdiRdi+1 is the transformation matrix that contains weights between two layers of perceptron 54.
4: The neural network received very much attention in academia and applications in engineering due to the proven universal approximation property which states that the feed-forward neural network architectures with a sigmoid activation function are capable of approximating any set of functions between two Euclidean spaces for the canonical topology 55.
